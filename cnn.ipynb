{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense , Dropout , Activation , Flatten \n",
    "from keras.layers.convolutional import Convolution2D , MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np \n",
    "from PIL import Image , ImageFile\n",
    "import theano\n",
    "theano.config.optimizer = 'None'\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/dm/Bureau/ISMAEL/CNN\")#/data/200.Common_Yellowthroat\")\n",
    "#img = Image.open(\"Common_Yellowthroat_0023_280227576.jpg\")\n",
    "#img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trav(img):\n",
    "    if img[0] == '.' or img[0] == '_':\n",
    "            img = img[1:]\n",
    "    if img[0] == '.' or img[0] == '_':\n",
    "            img = img[1:]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['004.Groove_billed_Ani', '005.Crested_Auklet', '001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross']\n",
      "1  sur  5\n",
      "004.Groove_billed_Ani\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "2  sur  5\n",
      "005.Crested_Auklet\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "3  sur  5\n",
      "001.Black_footed_Albatross\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "4  sur  5\n",
      "002.Laysan_Albatross\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "5  sur  5\n",
      "003.Sooty_Albatross\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "(296, 3, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "m,n = 50,50\n",
    "path1 = \"input\"\n",
    "path2 = \"Data\"\n",
    "classes = os.listdir(path2)\n",
    "X = []\n",
    "y = []\n",
    "def traiter(im):\n",
    "    im = im.convert(mode = 'RGB')\n",
    "    imrs = im.resize((m , n))\n",
    "    imrs = img_to_array(imrs)/255 #Normalization\n",
    "    imrs = imrs.transpose(2 , 0 , 1)\n",
    "    imrs=imrs.reshape(3 , m , n) #RGB\n",
    "    return imrs \n",
    "\n",
    "aff = False\n",
    "cpt = 0\n",
    "taille = len(classes)\n",
    "print(classes)\n",
    "for c in classes :\n",
    "    cpt+=1\n",
    "    print(cpt , \" sur \" , taille)\n",
    "    c = trav(c)\n",
    "    print(c)\n",
    "    imgfiles = os.listdir(path2+\"/\"+c) ; \n",
    "    i=0\n",
    "    for img in imgfiles:  \n",
    "        print(\"+\", end='')\n",
    "        img = trav(img)\n",
    "        #print(img)\n",
    "        im = Image.open(path2+\"/\"+c+\"/\"+img)\n",
    "        imrs = traiter(im)\n",
    "        if(i==0 and aff == True):\n",
    "            imrs.show()\n",
    "        i=1\n",
    "       \n",
    "        X.append(imrs)\n",
    "        y.append(c)\n",
    "    print(\"\")\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "nb_classes = len(classes)\n",
    "nb_epochs = 30\n",
    "nb_filters = 32\n",
    "nb_pool = 2\n",
    "nb_conv = 3 \n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X ,y , test_size=1/5 , random_state = 4)\n",
    "#to_categorical with string two steps\n",
    "uniques , id_train = np.unique(y_train , return_inverse = True) \n",
    "Y_train = np_utils.to_categorical(id_train , nb_classes)\n",
    "uniques , id_test = np.unique(y_test , return_inverse = True) \n",
    "Y_test = np_utils.to_categorical(id_test , nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dm/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(3, 50, 50..., padding=\"same\")`\n",
      "  \n",
      "/home/dm/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters , nb_conv , nb_conv ,border_mode = 'same' , input_shape = X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters , nb_conv , nb_conv , border_mode = 'same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dm/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 236 samples, validate on 60 samples\n",
      "Epoch 1/30\n",
      "236/236 [==============================] - 0s 895us/step - loss: 1.6337 - accuracy: 0.2585 - val_loss: 1.6393 - val_accuracy: 0.3167\n",
      "Epoch 2/30\n",
      "236/236 [==============================] - 0s 101us/step - loss: 1.6549 - accuracy: 0.2839 - val_loss: 1.9654 - val_accuracy: 0.2167\n",
      "Epoch 3/30\n",
      "236/236 [==============================] - 0s 108us/step - loss: 1.5234 - accuracy: 0.4110 - val_loss: 1.7348 - val_accuracy: 0.2167\n",
      "Epoch 4/30\n",
      "236/236 [==============================] - 0s 105us/step - loss: 1.5105 - accuracy: 0.4322 - val_loss: 1.5140 - val_accuracy: 0.2833\n",
      "Epoch 5/30\n",
      "236/236 [==============================] - 0s 112us/step - loss: 1.3100 - accuracy: 0.4449 - val_loss: 1.2519 - val_accuracy: 0.4833\n",
      "Epoch 6/30\n",
      "236/236 [==============================] - 0s 115us/step - loss: 1.2260 - accuracy: 0.5212 - val_loss: 2.3295 - val_accuracy: 0.1167\n",
      "Epoch 7/30\n",
      "236/236 [==============================] - 0s 112us/step - loss: 1.3170 - accuracy: 0.4788 - val_loss: 2.5839 - val_accuracy: 0.2667\n",
      "Epoch 8/30\n",
      "236/236 [==============================] - 0s 116us/step - loss: 1.4860 - accuracy: 0.5085 - val_loss: 1.1726 - val_accuracy: 0.4667\n",
      "Epoch 9/30\n",
      "236/236 [==============================] - 0s 117us/step - loss: 1.1381 - accuracy: 0.5636 - val_loss: 1.4031 - val_accuracy: 0.3333\n",
      "Epoch 10/30\n",
      "236/236 [==============================] - 0s 109us/step - loss: 0.9550 - accuracy: 0.6483 - val_loss: 1.0378 - val_accuracy: 0.5167\n",
      "Epoch 11/30\n",
      "236/236 [==============================] - 0s 112us/step - loss: 0.8879 - accuracy: 0.6441 - val_loss: 0.8992 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "236/236 [==============================] - 0s 117us/step - loss: 0.7813 - accuracy: 0.6992 - val_loss: 1.2904 - val_accuracy: 0.5167\n",
      "Epoch 13/30\n",
      "236/236 [==============================] - 0s 107us/step - loss: 1.2374 - accuracy: 0.5297 - val_loss: 0.8824 - val_accuracy: 0.6500\n",
      "Epoch 14/30\n",
      "236/236 [==============================] - 0s 107us/step - loss: 0.6805 - accuracy: 0.7500 - val_loss: 1.0213 - val_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "236/236 [==============================] - 0s 116us/step - loss: 0.6375 - accuracy: 0.7881 - val_loss: 0.9359 - val_accuracy: 0.6500\n",
      "Epoch 16/30\n",
      "236/236 [==============================] - 0s 105us/step - loss: 0.5264 - accuracy: 0.7966 - val_loss: 0.7572 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "236/236 [==============================] - 0s 124us/step - loss: 0.4948 - accuracy: 0.8432 - val_loss: 0.8713 - val_accuracy: 0.6667\n",
      "Epoch 18/30\n",
      "236/236 [==============================] - 0s 110us/step - loss: 0.5520 - accuracy: 0.8136 - val_loss: 1.3141 - val_accuracy: 0.6167\n",
      "Epoch 19/30\n",
      "236/236 [==============================] - 0s 105us/step - loss: 0.4974 - accuracy: 0.8390 - val_loss: 0.7897 - val_accuracy: 0.7667\n",
      "Epoch 20/30\n",
      "236/236 [==============================] - 0s 118us/step - loss: 0.5126 - accuracy: 0.8347 - val_loss: 0.5931 - val_accuracy: 0.7667\n",
      "Epoch 21/30\n",
      "236/236 [==============================] - 0s 117us/step - loss: 0.2773 - accuracy: 0.9280 - val_loss: 0.8441 - val_accuracy: 0.6667\n",
      "Epoch 22/30\n",
      "236/236 [==============================] - 0s 102us/step - loss: 0.2933 - accuracy: 0.9237 - val_loss: 0.7272 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "236/236 [==============================] - 0s 112us/step - loss: 0.2057 - accuracy: 0.9576 - val_loss: 0.5328 - val_accuracy: 0.7833\n",
      "Epoch 24/30\n",
      "236/236 [==============================] - 0s 115us/step - loss: 0.2677 - accuracy: 0.9153 - val_loss: 1.2469 - val_accuracy: 0.5333\n",
      "Epoch 25/30\n",
      "236/236 [==============================] - 0s 103us/step - loss: 0.2592 - accuracy: 0.9280 - val_loss: 0.5833 - val_accuracy: 0.8167\n",
      "Epoch 26/30\n",
      "236/236 [==============================] - 0s 104us/step - loss: 0.1438 - accuracy: 0.9703 - val_loss: 1.2783 - val_accuracy: 0.5667\n",
      "Epoch 27/30\n",
      "236/236 [==============================] - 0s 106us/step - loss: 0.3072 - accuracy: 0.8983 - val_loss: 0.4468 - val_accuracy: 0.9000\n",
      "Epoch 28/30\n",
      "236/236 [==============================] - 0s 107us/step - loss: 0.1112 - accuracy: 0.9873 - val_loss: 0.5611 - val_accuracy: 0.8667\n",
      "Epoch 29/30\n",
      "236/236 [==============================] - 0s 109us/step - loss: 0.0972 - accuracy: 0.9831 - val_loss: 0.5067 - val_accuracy: 0.8167\n",
      "Epoch 30/30\n",
      "236/236 [==============================] - 0s 112us/step - loss: 0.0873 - accuracy: 0.9915 - val_loss: 0.4679 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6a047ae5c0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adadelta' , metrics = ['accuracy'])\n",
    "model.fit(\n",
    "    X_train , \n",
    "        Y_train , \n",
    "            batch_size = batch_size , \n",
    "                nb_epoch = nb_epochs , \n",
    "                    verbose = 1 , \n",
    "                        validation_data = (X_test , Y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path1)\n",
    "v = []\n",
    "f = []\n",
    "for cpt in range(len(files)):    \n",
    "    img = Image.open(path1 + \"/\" + files[cpt])\n",
    "    f.append(files[cpt])\n",
    "    imrs=traiter(img)\n",
    "    v.append(imrs)\n",
    "v = np.array(v)\n",
    "pred = model.predict(v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black_footed_Albatross_0002_2293084168.jpg\n",
      "001.Black_footed_Albatross\n",
      "    ++++\n",
      "Groove_billed_Ani_0008_402320965.jpg\n",
      "004.Groove_billed_Ani\n",
      "    ++++\n",
      "Crested_Auklet_0012_751253546.jpg\n",
      "005.Crested_Auklet\n",
      "    ++++\n",
      "Laysan_Albatross_0018_2755886291.jpg\n",
      "002.Laysan_Albatross\n",
      "    ++++\n",
      "Crested_Auklet_0018_1297094698.jpg\n",
      "005.Crested_Auklet\n",
      "    ++++\n",
      "Sooty_Albatross_0015_496189203.jpg\n",
      "003.Sooty_Albatross\n",
      "    ++++\n",
      "Laysan_Albatross_0011_2783435831.jpg\n",
      "002.Laysan_Albatross\n",
      "    ++++\n",
      "Groove_billed_Ani_0024_3001839411.jpg\n",
      "004.Groove_billed_Ani\n",
      "    ++++\n",
      "Laysan_Albatross_0007_2761419013.jpg\n",
      "002.Laysan_Albatross\n",
      "    ++++\n",
      "Sooty_Albatross_0013_496156286.jpg\n",
      "003.Sooty_Albatross\n",
      "    ++++\n",
      "Groove_billed_Ani_0033_2267259581.jpg\n",
      "004.Groove_billed_Ani\n",
      "    ++++\n",
      "Crested_Auklet_0008_2771761648.jpg\n",
      "005.Crested_Auklet\n",
      "    ++++\n",
      "Sooty_Albatross_0017_391297426.jpg\n",
      "003.Sooty_Albatross\n",
      "    ++++\n",
      "Black_footed_Albatross_0007_2675126617.jpg\n",
      "001.Black_footed_Albatross\n",
      "    ++++\n",
      "Crested_Auklet_0015_2484284075.jpg\n",
      "005.Crested_Auklet\n",
      "    ++++\n",
      "Laysan_Albatross_0008_2425914750.jpg\n",
      "002.Laysan_Albatross\n",
      "    ++++\n",
      "Black_footed_Albatross_0010_819241733.jpg\n",
      "001.Black_footed_Albatross\n",
      "    ++++\n",
      "Black_footed_Albatross_0017_1256111444.jpg\n",
      "001.Black_footed_Albatross\n",
      "    ++++\n",
      "Laysan_Albatross_0015_313326964.jpg\n",
      "002.Laysan_Albatross\n",
      "    ++++\n",
      "Sooty_Albatross_0020_2180373314.jpg\n",
      "003.Sooty_Albatross\n",
      "    ++++\n",
      "Black_footed_Albatross_0014_2446379278.jpg\n",
      "001.Black_footed_Albatross\n",
      "    ++++\n",
      "Groove_billed_Ani_0012_2410652192.jpg\n",
      "004.Groove_billed_Ani\n",
      "    ++++\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(pred)) : \n",
    "    #print(p)\n",
    "    i = np.argmax(pred[p])\n",
    "    print(f[p])\n",
    "    print(uniques[i])\n",
    "    print(\"    ++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crested_Auklet_0015_2484284075.jpg\n",
      "[[2.3804258e-03 2.3862082e-04 2.3837984e-03 5.9046462e-04 9.9440670e-01]]\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(path1)\n",
    "im = Image.open(path1 + \"/\" + files[14])\n",
    "print(files[14])\n",
    "imrs = traiter(im)\n",
    "v = []\n",
    "v.append(imrs)\n",
    "v = np.array(v)\n",
    "pred = model.predict(v)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
